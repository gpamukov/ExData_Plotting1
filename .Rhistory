# Standardize variable names (convert to tidy format) - remove all non alphanumeric characters and lowercase
names(extract_data_dt) <- gsub("\\W", "", tolower(names(extract_data_dt)))
# Lookup activity labels and format final tidy non agregated set
activity_labels_dt <- read.table(file.path(data_dir, "UCI HAR Dataset/activity_labels.txt"), sep=" ", col.names = c("activitylabelid", "activitylabel"), stringsAsFactors = TRUE)
tidy_data_full_dt <- left_join(extract_data_dt, activity_labels_dt)
# Remove temp variables
extract_data_dt <- NULL
activity_labels_dt <- NULL
str(tidy_data_full_dt)
tidy_data_full_dt <- tidy_data_full_dt %>% remove(activitylabelid)
str(tidy_data_full_dt)
test_dt <- prep_dataset("test")
# Prepare train data set
train_dt <- prep_dataset("train")
# Merge train and test sets togeteher (union all)
raw_data_dt <- rbind(test_dt, train_dt)
str(raw_data_dt)
# Clean the temp variables
test_dt <- NULL
train_dt <- NULL
# Extract mean and std ======================================================================================
# Extract only variables that are needed (measurements on the mean and standard deviation for each measurement)
extract_data_dt <- raw_data_dt %>% select(subjectid, activitylabelid, matches("(mean\\.{2,}[xyz]*$|std\\.{2,}[xyz]*$)"))
# Remove temp variable
raw_data_dt <- NULL
# Tidy the extracted set  ===================================================================================
# Standardize variable names (convert to tidy format) - remove all non alphanumeric characters and lowercase
names(extract_data_dt) <- gsub("\\W", "", tolower(names(extract_data_dt)))
# Lookup activity labels and format final tidy non agregated set
activity_labels_dt <- read.table(file.path(data_dir, "UCI HAR Dataset/activity_labels.txt"), sep=" ", col.names = c("activitylabelid", "activitylabel"), stringsAsFactors = TRUE)
tidy_data_full_dt <- left_join(extract_data_dt, activity_labels_dt)
# Remove temp variables
extract_data_dt <- NULL
activity_labels_dt <- NULL
str(tidy_data_full_dt)
str(tidy_data_full_dt)
tidy_data_full_dt %>% remove(activitylabelid)
test_dt <- prep_dataset("test")
# Prepare train data set
train_dt <- prep_dataset("train")
# Merge train and test sets togeteher (union all)
raw_data_dt <- rbind(test_dt, train_dt)
str(raw_data_dt)
# Clean the temp variables
test_dt <- NULL
train_dt <- NULL
# Extract mean and std ======================================================================================
# Extract only variables that are needed (measurements on the mean and standard deviation for each measurement)
extract_data_dt <- raw_data_dt %>% select(subjectid, activitylabelid, matches("(mean\\.{2,}[xyz]*$|std\\.{2,}[xyz]*$)"))
# Remove temp variable
raw_data_dt <- NULL
# Tidy the extracted set  ===================================================================================
# Standardize variable names (convert to tidy format) - remove all non alphanumeric characters and lowercase
names(extract_data_dt) <- gsub("\\W", "", tolower(names(extract_data_dt)))
# Lookup activity labels and format final tidy non agregated set
activity_labels_dt <- read.table(file.path(data_dir, "UCI HAR Dataset/activity_labels.txt"), sep=" ", col.names = c("activitylabelid", "activitylabel"), stringsAsFactors = TRUE)
tidy_data_full_dt <- left_join(extract_data_dt, activity_labels_dt) %>% select(-activitylabelid)
str(tidy_data_full_dt)
re
## =========================================================================================================
data_dir <- "./data"
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
dest_file <- "project_data.zip"
## =========================================================================================================
## FUNCTIONS
## =========================================================================================================
# Create relevant file names and paths (based on set_name parameter) for:
# * subject
# * label
# * data
# Bind in one set, clean temp variables and output
prep_dataset <- function (set_name){
# Read Subjects
subject_file_name <- paste("subject_", set_name, ".txt", sep = "")
subject_file_path <- file.path(data_dir, "UCI HAR Dataset", set_name, subject_file_name, fsep = .Platform$file.sep)
subject_dt <- fread(input = subject_file_path, header = FALSE, col.names = c("subjectid"), data.table = TRUE)
# Read Labels
label_file_name <- paste("y_", set_name, ".txt", sep = "")
label_file_path <- file.path(data_dir, "UCI HAR Dataset", set_name, label_file_name, fsep = .Platform$file.sep)
label_dt <- fread(input = label_file_path, header = FALSE, col.names = c("activitylabelid"), data.table = TRUE)
# Read Data
data_file_name <- paste("X_", set_name, ".txt", sep = "")
data_file_path <- file.path(data_dir, "UCI HAR Dataset", set_name, data_file_name, fsep = .Platform$file.sep)
# Read column names from features.txt and transform in valid variable names (rename if needed to make unique)
data_file_col_names <- make.names((read.table(file.path(data_dir, "UCI HAR Dataset/features.txt"), sep=" ", stringsAsFactors = FALSE))$V2, unique = TRUE)
data_dt <- fread(input = data_file_path, header = FALSE, col.names = c(data_file_col_names), data.table = TRUE)
# Column bind all parts to create final raw set
data <- cbind(subject_dt, label_dt, data_dt)
# Clean up the mess
subject_dt <- NULL
label_dt <- NULL
data_dt <- NULL
data
}
## =========================================================================================================
## BEGINNING OF MAIN
## =========================================================================================================
# Retrieve dataset from the web to guarantee reproducible result ===========================================
# This section can be commeneted if dataset already available
# Download zip archive with the data
if(!file.exists(data_dir)){dir.create(data_dir)}
dest_file_full_pth <- file.path(data_dir, dest_file, fsep = .Platform$file.sep)
download.file(url, destfile = dest_file_full_pth, mode = "wb") # download binary
# Extract archive in data directory
unzip(dest_file_full_pth, files = NULL, list = FALSE, overwrite = TRUE, junkpaths = FALSE, exdir = data_dir, unzip = "internal", setTimes = FALSE)
# Combine init raw data set =================================================================================
# Prepare test data set
test_dt <- prep_dataset("test")
# Prepare train data set
train_dt <- prep_dataset("train")
# Merge train and test sets togeteher (union all)
raw_data_dt <- rbind(test_dt, train_dt)
str(raw_data_dt)
# Clean the temp variables
test_dt <- NULL
train_dt <- NULL
# Extract mean and std ======================================================================================
# Extract only variables that are needed (measurements on the mean and standard deviation for each measurement)
extract_data_dt <- raw_data_dt %>% select(subjectid, activitylabelid, matches("(mean\\.{2,}[xyz]*$|std\\.{2,}[xyz]*$)"))
# Remove temp variable
raw_data_dt <- NULL
# Tidy the extracted set  ===================================================================================
# Standardize variable names (convert to tidy format) - remove all non alphanumeric characters and lowercase
names(extract_data_dt) <- gsub("\\W", "", tolower(names(extract_data_dt)))
# Lookup activity labels and format final tidy non agregated set
activity_labels_dt <- read.table(file.path(data_dir, "UCI HAR Dataset/activity_labels.txt"), sep=" ", col.names = c("activitylabelid", "activitylabel"), stringsAsFactors = TRUE)
tidy_data_full_dt <- left_join(extract_data_dt, activity_labels_dt) %>% select(-activitylabelid) %>% select(subjectid, activitylabel, tbodyaccmeanx:fbodybodygyrojerkmagstd)
# Remove temp variables
extract_data_dt <- NULL
activity_labels_dt <- NULL
str(tidy_data_full_dt)
table(tidy_data_full_dt$subjectid, tidy_data_full_dt$activitylabel)
table(tidy_data_full_dt$subjectid)
tidy_data_full_dt %>% group_by(subjectid, activitylabel) %>% summarise_each(funs(mean))
tidy_data_aggr_dt <- tidy_data_full_dt %>% group_by(subjectid, activitylabel) %>% summarise_each(funs(mean))
str(tidy_data_aggr_dt)
sapply(names(tidy_data_aggr_dt), fun = function (x){if (grep('(mean|std)',x) == TRUE){1}else{x}})
sapply(names(tidy_data_aggr_dt), FUN = function (x){if (grep('(mean|std)',x) == TRUE){1}else{x}})
grep('mean', 'fbodybodyaccjerkmagmean')
grep('mean', 'fbodybodyaccjerkmagman')
sapply(names(tidy_data_aggr_dt), FUN = function (x){if (length(grep('(mean|std)',x)) > 0){1}else{x}})
names(tidy_data_aggr_dt) <- sapply(names(tidy_data_aggr_dt), FUN = function (x){if (length(grep('(mean|std)',x)) > 0){paste('averageof', x, sep = "")}else{x}})
names(tidy_data_aggr_dt)
## =========================================================================================================
## Author: Georgi Pamukov
## Date: 2016/07/24
## Description: Packs methods to hold, process (inverse) and cache matrix data
##
## =========================================================================================================
## =========================================================================================================
## LIBRARIES
## =========================================================================================================
library(dplyr)
library(data.table)
## =========================================================================================================
## VARIABLES AND FILES - can change configuration here
## =========================================================================================================
data_dir <- "./data"
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
dest_file <- "project_data.zip"
## =========================================================================================================
## FUNCTIONS
## =========================================================================================================
# Create relevant file names and paths (based on set_name parameter) for:
# * subject
# * label
# * data
# Bind in one set, clean temp variables and output
prep_dataset <- function (set_name){
# Read Subjects
subject_file_name <- paste("subject_", set_name, ".txt", sep = "")
subject_file_path <- file.path(data_dir, "UCI HAR Dataset", set_name, subject_file_name, fsep = .Platform$file.sep)
subject_dt <- fread(input = subject_file_path, header = FALSE, col.names = c("subjectid"), data.table = TRUE)
# Read Labels
label_file_name <- paste("y_", set_name, ".txt", sep = "")
label_file_path <- file.path(data_dir, "UCI HAR Dataset", set_name, label_file_name, fsep = .Platform$file.sep)
label_dt <- fread(input = label_file_path, header = FALSE, col.names = c("activitylabelid"), data.table = TRUE)
# Read Data
data_file_name <- paste("X_", set_name, ".txt", sep = "")
data_file_path <- file.path(data_dir, "UCI HAR Dataset", set_name, data_file_name, fsep = .Platform$file.sep)
# Read column names from features.txt and transform in valid variable names (rename if needed to make unique)
data_file_col_names <- make.names((read.table(file.path(data_dir, "UCI HAR Dataset/features.txt"), sep=" ", stringsAsFactors = FALSE))$V2, unique = TRUE)
data_dt <- fread(input = data_file_path, header = FALSE, col.names = c(data_file_col_names), data.table = TRUE)
# Column bind all parts to create final raw set
data <- cbind(subject_dt, label_dt, data_dt)
# Clean up the mess
subject_dt <- NULL
label_dt <- NULL
data_dt <- NULL
data
}
## =========================================================================================================
## BEGINNING OF MAIN
## =========================================================================================================
# Retrieve dataset from the web to guarantee reproducible result ===========================================
# This section can be commeneted if dataset already available
# Download zip archive with the data
if(!file.exists(data_dir)){dir.create(data_dir)}
dest_file_full_pth <- file.path(data_dir, dest_file, fsep = .Platform$file.sep)
download.file(url, destfile = dest_file_full_pth, mode = "wb") # download binary
# Extract archive in data directory
unzip(dest_file_full_pth, files = NULL, list = FALSE, overwrite = TRUE, junkpaths = FALSE, exdir = data_dir, unzip = "internal", setTimes = FALSE)
# Combine init raw data set =================================================================================
# Prepare test data set
test_dt <- prep_dataset("test")
# Prepare train data set
train_dt <- prep_dataset("train")
# Merge train and test sets togeteher (union all)
raw_data_dt <- rbind(test_dt, train_dt)
str(raw_data_dt)
# Clean the temp variables
test_dt <- NULL
train_dt <- NULL
# Extract mean and std ======================================================================================
# Extract only variables that are needed (measurements on the mean and standard deviation for each measurement)
extract_data_dt <- raw_data_dt %>% select(subjectid, activitylabelid, matches("(mean\\.{2,}[xyz]*$|std\\.{2,}[xyz]*$)"))
# Remove temp variable
raw_data_dt <- NULL
# Tidy the extracted set  ===================================================================================
# Standardize variable names (convert to tidy format) - remove all non alphanumeric characters and lowercase
names(extract_data_dt) <- gsub("\\W", "", tolower(names(extract_data_dt)))
# Lookup activity labels and format final tidy non agregated set
activity_labels_dt <- read.table(file.path(data_dir, "UCI HAR Dataset/activity_labels.txt"), sep=" ", col.names = c("activitylabelid", "activitylabel"), stringsAsFactors = TRUE)
tidy_data_full_dt <- left_join(extract_data_dt, activity_labels_dt) %>% select(-activitylabelid) %>% select(subjectid, activitylabel, tbodyaccmeanx:fbodybodygyrojerkmagstd)
# Remove temp variables
extract_data_dt <- NULL
activity_labels_dt <- NULL
# Create tidy aggregated set  ===============================================================================
# Aggregate and create independent tidy data set with the average of each variable for each activity and each subject
tidy_data_aggr_dt <- tidy_data_full_dt %>% group_by(subjectid, activitylabel) %>% summarise_each(funs(mean))
# Apply proper column names on the aggregated set variables
names(tidy_data_aggr_dt) <- sapply(names(tidy_data_aggr_dt), FUN = function (x){if (length(grep('(mean|std)',x)) > 0){paste('averageof', x, sep = "")}else{x}})
# Output final aggregated set  ==============================================================================
write.table(tidy_data_aggr_dt, file.path(data_dir, "human_activity_recognition_using_smartphones_aggregated_dataset.txt", fsep = .Platform$file.sep), row.name = FALSE)
## =========================================================================================================
## Author: Georgi Pamukov
## Date: 2016/07/24
## Description: Packs methods to hold, process (inverse) and cache matrix data
##
## =========================================================================================================
## =========================================================================================================
## LIBRARIES
## =========================================================================================================
library(dplyr)
library(data.table)
## =========================================================================================================
## VARIABLES AND FILES - can change configuration here
## =========================================================================================================
data_dir <- "./data"
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
dest_file <- "project_data.zip"
## =========================================================================================================
## FUNCTIONS
## =========================================================================================================
# Create relevant file names and paths (based on set_name parameter) for:
# * subject
# * label
# * data
# Bind in one set, clean temp variables and output
prep_dataset <- function (set_name){
# Read Subjects
subject_file_name <- paste("subject_", set_name, ".txt", sep = "")
subject_file_path <- file.path(data_dir, "UCI HAR Dataset", set_name, subject_file_name, fsep = .Platform$file.sep)
subject_dt <- fread(input = subject_file_path, header = FALSE, col.names = c("subjectid"), data.table = TRUE)
# Read Labels
label_file_name <- paste("y_", set_name, ".txt", sep = "")
label_file_path <- file.path(data_dir, "UCI HAR Dataset", set_name, label_file_name, fsep = .Platform$file.sep)
label_dt <- fread(input = label_file_path, header = FALSE, col.names = c("activitylabelid"), data.table = TRUE)
# Read Data
data_file_name <- paste("X_", set_name, ".txt", sep = "")
data_file_path <- file.path(data_dir, "UCI HAR Dataset", set_name, data_file_name, fsep = .Platform$file.sep)
# Read column names from features.txt and transform in valid variable names (rename if needed to make unique)
data_file_col_names <- make.names((read.table(file.path(data_dir, "UCI HAR Dataset/features.txt"), sep=" ", stringsAsFactors = FALSE))$V2, unique = TRUE)
data_dt <- fread(input = data_file_path, header = FALSE, col.names = c(data_file_col_names), data.table = TRUE)
# Column bind all parts to create final raw set
data <- cbind(subject_dt, label_dt, data_dt)
# Clean up the mess
subject_dt <- NULL
label_dt <- NULL
data_dt <- NULL
data
}
## =========================================================================================================
## BEGINNING OF MAIN
## =========================================================================================================
# Retrieve dataset from the web to guarantee reproducible result ===========================================
# This section can be commeneted if dataset already available
# Download zip archive with the data
if(!file.exists(data_dir)){dir.create(data_dir)}
dest_file_full_pth <- file.path(data_dir, dest_file, fsep = .Platform$file.sep)
download.file(url, destfile = dest_file_full_pth, mode = "wb") # download binary
# Extract archive in data directory
unzip(dest_file_full_pth, files = NULL, list = FALSE, overwrite = TRUE, junkpaths = FALSE, exdir = data_dir, unzip = "internal", setTimes = FALSE)
# Combine init raw data set =================================================================================
# Prepare test data set
test_dt <- prep_dataset("test")
# Prepare train data set
train_dt <- prep_dataset("train")
# Merge train and test sets togeteher (union all)
raw_data_dt <- rbind(test_dt, train_dt)
str(raw_data_dt)
# Clean the temp variables
test_dt <- NULL
train_dt <- NULL
# Extract mean and std ======================================================================================
# Extract only variables that are needed (measurements on the mean and standard deviation for each measurement)
extract_data_dt <- raw_data_dt %>% select(subjectid, activitylabelid, matches("(mean\\.{2,}[xyz]*$|std\\.{2,}[xyz]*$)"))
# Remove temp variable
raw_data_dt <- NULL
# Tidy the extracted set  ===================================================================================
# Standardize variable names (convert to tidy format) - remove all non alphanumeric characters and lowercase
names(extract_data_dt) <- gsub("\\W", "", tolower(names(extract_data_dt)))
# Lookup activity labels and format final tidy non agregated set
activity_labels_dt <- read.table(file.path(data_dir, "UCI HAR Dataset/activity_labels.txt"), sep=" ", col.names = c("activitylabelid", "activitylabel"), stringsAsFactors = TRUE)
tidy_data_full_dt <- left_join(extract_data_dt, activity_labels_dt) %>% select(-activitylabelid) %>% select(subjectid, activitylabel, tbodyaccmeanx:fbodybodygyrojerkmagstd)
# Remove temp variables
extract_data_dt <- NULL
activity_labels_dt <- NULL
# Create tidy aggregated set  ===============================================================================
# Aggregate and create independent tidy data set with the average of each variable for each activity and each subject
tidy_data_aggr_dt <- tidy_data_full_dt %>% group_by(subjectid, activitylabel) %>% summarise_each(funs(mean))
# Apply proper column names on the aggregated set variables
names(tidy_data_aggr_dt) <- sapply(names(tidy_data_aggr_dt), FUN = function (x){if (length(grep('(mean|std)',x)) > 0){paste('averageof', x, sep = "")}else{x}})
# Output final aggregated set  ==============================================================================
write.table(tidy_data_aggr_dt, file.path(data_dir, "UCI_HAR_Agg_Dataset.txt", fsep = .Platform$file.sep), row.name = FALSE)
str(tidy_data_aggr_dt)
str(tidy_data_aggr_dt)
file.path(data_dir, "UCI_HAR_Agg_Dataset.txt", fsep = .Platform$file.sep)
write.table(x = tidy_data_aggr_dt, file = file.path(data_dir, "UCI_HAR_Agg_Dataset.txt", fsep = .Platform$file.sep), row.names = FALSE)
getwd()
getwd()
setwd("C:\Users\georgi.pamukov\Documents\GitHub\ExData_Plotting1\ExData_Plotting1")
setwd("C:\\Users\\georgi.pamukov\\Documents\\GitHub\\ExData_Plotting1\\ExData_Plotting1")
## =========================================================================================================
## Author: Georgi Pamukov
## Date: 2016/07/24
## Description:
## Performs the following actions:
## * downloads data from https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip
## * reads only data for 2007-02-01 and 2007-02-02
## * generates plot1 as per requirements and outputs to png
## Reqiured libraries: dplyr, data.table
## =========================================================================================================
## =========================================================================================================
## LIBRARIES
## =========================================================================================================
#library(dplyr)
#library(data.table)
## =========================================================================================================
## VARIABLES AND FILES - can change configuration here
## =========================================================================================================
data_dir <- "./data"
url <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip"
dest_file <- "project_data.zip"
## =========================================================================================================
## BEGINNING OF MAIN
## =========================================================================================================
# Retrieve dataset from the web to guarantee reproducible result ===========================================
# This section can be commeneted if dataset already available
# Download zip archive with the data
if(!file.exists(data_dir)){dir.create(data_dir)}
dest_file_full_pth <- file.path(data_dir, dest_file, fsep = .Platform$file.sep)
download.file(url, destfile = dest_file_full_pth, mode = "wb") # download binary
# Extract archive in data directory
unzip(dest_file_full_pth, files = NULL, list = FALSE, overwrite = TRUE, junkpaths = FALSE, exdir = data_dir, unzip = "internal", setTimes = FALSE)
## =========================================================================================================
## Author: Georgi Pamukov
## Date: 2016/07/24
## Description:
## Performs the following actions:
## * downloads data from https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip
## * reads only data for 2007-02-01 and 2007-02-02
## * generates plot1 as per requirements and outputs to png
## Reqiured libraries: dplyr, data.table
## =========================================================================================================
## =========================================================================================================
## LIBRARIES
## =========================================================================================================
#library(dplyr)
#library(data.table)
## =========================================================================================================
## VARIABLES AND FILES - can change configuration here
## =========================================================================================================
data_dir <- "./data"
url <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip"
dest_file <- "project_data.zip"
raw_file_name <- "household_power_consumption.txt"
## =========================================================================================================
## BEGINNING OF MAIN
## =========================================================================================================
# Retrieve dataset from the web to guarantee reproducible result ===========================================
# Will not try to download if dataset already available
# Download zip archive with the data
if(!file.exists(data_dir)){dir.create(data_dir)}
if(!file.exists(file.path(data_dir, raw_file_name, fsep = .Platform$file.sep))){
dest_file_full_pth <- file.path(data_dir, dest_file, fsep = .Platform$file.sep)
download.file(url, destfile = dest_file_full_pth, mode = "wb") # download binary
# Extract archive in data directory
unzip(dest_file_full_pth, files = NULL, list = FALSE, overwrite = TRUE, junkpaths = FALSE, exdir = data_dir, unzip = "internal", setTimes = FALSE)
}
## =========================================================================================================
## Author: Georgi Pamukov
## Date: 2016/07/24
## Description:
## Performs the following actions:
## * downloads data from https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip
## * reads only data for 2007-02-01 and 2007-02-02
## * generates plot1 as per requirements and outputs to png
## Reqiured libraries: dplyr, data.table
## =========================================================================================================
## =========================================================================================================
## LIBRARIES
## =========================================================================================================
#library(dplyr)
#library(data.table)
## =========================================================================================================
## VARIABLES AND FILES - can change configuration here
## =========================================================================================================
data_dir <- "./data"
url <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip"
dest_file <- "project_data.zip"
raw_file_name <- "household_power_consumption.txt"
## =========================================================================================================
## BEGINNING OF MAIN
## =========================================================================================================
# Retrieve dataset from the web to guarantee reproducible result ===========================================
# Will not try to download if dataset already available
# Download zip archive with the data
if(!file.exists(data_dir)){dir.create(data_dir)}
if(!file.exists(file.path(data_dir, raw_file_name, fsep = .Platform$file.sep))){
dest_file_full_pth <- file.path(data_dir, dest_file, fsep = .Platform$file.sep)
download.file(url, destfile = dest_file_full_pth, mode = "wb") # download binary
# Extract archive in data directory
unzip(dest_file_full_pth, files = NULL, list = FALSE, overwrite = TRUE, junkpaths = FALSE, exdir = data_dir, unzip = "internal", setTimes = FALSE)
}
data_dir <- "./data"
url <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip"
dest_file <- "project_data.zip"
raw_file_name <- "household_power_consumption.txt"
## =========================================================================================================
## BEGINNING OF MAIN
## =========================================================================================================
# Retrieve dataset from the web to guarantee reproducible result ===========================================
# Will not try to download if dataset already available
# Download zip archive with the data
if(!file.exists(data_dir)){dir.create(data_dir)}
if(!file.exists(file.path(data_dir, raw_file_name, fsep = .Platform$file.sep))){
dest_file_full_pth <- file.path(data_dir, dest_file, fsep = .Platform$file.sep)
download.file(url, destfile = dest_file_full_pth, mode = "wb") # download binary
# Extract archive in data directory
unzip(dest_file_full_pth, files = NULL, list = FALSE, overwrite = TRUE, junkpaths = FALSE, exdir = data_dir, unzip = "internal", setTimes = FALSE)
}
library(data.table)
library(dplyr)
?fread()
## =========================================================================================================
## LIBRARIES
## =========================================================================================================
library(dplyr)
library(data.table)
## =========================================================================================================
## VARIABLES AND FILES - can change configuration here
## =========================================================================================================
data_dir <- "./data"
url <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip"
dest_file <- "project_data.zip"
raw_file_name <- "household_power_consumption.txt"
## =========================================================================================================
## BEGINNING OF MAIN
## =========================================================================================================
# Retrieve dataset from the web to guarantee reproducible result ===========================================
# Will not try to download if dataset already available
# Download zip archive with the data
raw_file_path <- file.path(data_dir, raw_file_name, fsep = .Platform$file.sep)
if(!file.exists(data_dir)){dir.create(data_dir)}
if(!file.exists(raw_file_path)){
dest_file_full_pth <- file.path(data_dir, dest_file, fsep = .Platform$file.sep)
download.file(url, destfile = dest_file_full_pth, mode = "wb") # download binary
# Extract archive in data directory
unzip(dest_file_full_pth, files = NULL, list = FALSE, overwrite = TRUE, junkpaths = FALSE, exdir = data_dir, unzip = "internal", setTimes = FALSE)
}
data_dt <- fread(input = raw_file_path, data.table = TRUE) %>% filter(Date %in% c('01/02/2007', '02/02/2007'))
data_dt <- fread(input = raw_file_path, na.strings = '?' ,data.table = TRUE) %>% filter(Date %in% c('01/02/2007', '02/02/2007'))
str(data_dt)
data_dt <- fread(input = raw_file_path, na.strings = '?' ,data.table = TRUE) %>% filter(Date %in% c("1/2/2007", "2/2/2007"))
str(data_dt)
1440*2
library(lubridate)
data_dt <- fread(input = raw_file_path, na.strings = '?' ,data.table = TRUE) %>% filter(Date %in% c("1/2/2007", "2/2/2007")) %>% mutate(Date = dmy(Date)
data_dt <- fread(input = raw_file_path, na.strings = '?' ,data.table = TRUE) %>% filter(Date %in% c("1/2/2007", "2/2/2007")) %>% mutate(Date = dmy(Date))
data_dt <- fread(input = raw_file_path, na.strings = '?' ,data.table = TRUE) %>% filter(Date %in% c("1/2/2007", "2/2/2007")) %>% mutate(Date = dmy(Date))
str(data)
str(data_dt)
data_dt <- fread(input = raw_file_path, na.strings = '?' ,data.table = TRUE) %>% filter(Date %in% c("1/2/2007", "2/2/2007")) %>% mutate(Date = dmy(Date), Time = hms(Time))
str(data_dt)
head(data_dt)
data_dt <- fread(input = raw_file_path, na.strings = '?' ,data.table = TRUE) %>% filter(Date %in% c("1/2/2007", "2/2/2007")) %>% mutate(DateTime = dmy_hms(paste(Date, Time, sep = "")))
data_dt <- fread(input = raw_file_path, na.strings = '?' ,data.table = TRUE) %>% filter(Date %in% c("1/2/2007", "2/2/2007")) %>% mutate(DateTime = dmy_hms(paste(Date, Time, sep = " ")))
paste("1/2/2007", "2/2/2007", sep = " ")
str(data_dt)
head(data_dt)
with(data_dt, hist(Global_active_power))
?hist()
with(data_dt, hist(Global_active_power, main = "Global Active Power", xlab = "Global Active Power (kilowatts)"))
with(data_dt, hist(Global_active_power, main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "red"))
dev.copy(png, filename = "plot1.png", width = 480, height = 480, units = "px")
dev.off
dev.off
with(data_dt, hist(Global_active_power, main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "red"))
png(filename = "plot1.png", width = 480, height = 480, units = "px")
with(data_dt, hist(Global_active_power, main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "red"))
dev.off
